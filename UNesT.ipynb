{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72a94f93-b2a8-4c58-ba9f-3d6cf6c3b23b",
   "metadata": {},
   "source": [
    "# UNest Model Inference Tutorial\n",
    "\n",
    "This tutorial explains how to use the trained UNesT model with 87 HOA subjects for inference. The model is available in this repository, and below are the steps to set up your environment, and perform inference.\n",
    "We trained the Unest_large which is developped by [MASILab](https://github.com/MASILab/UNesT/blob/main/wholebrainSeg/README.md) \n",
    "\n",
    "## Prerequisites\n",
    "- Python 3.8.0\n",
    "\n",
    "\n",
    "\n",
    "Follow along with explanations below!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317ecfe0-0ae3-4438-9366-7657c108806b",
   "metadata": {},
   "source": [
    "## Environment\n",
    "You can install the required libraries with requiremnts.txt. Narval-compatible versions can be installed using Narval-requiremnts.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ba8de4-3306-4498-bcfa-7949f969cd22",
   "metadata": {},
   "source": [
    "## Register images to the MNI-305space\n",
    "First you need to register the images from their original space to MNI space. You can use ants_registration.py file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588b23ee-ae94-4da4-b423-da035ecfc655",
   "metadata": {},
   "source": [
    "## Download the Models\n",
    "\n",
    "The trained UNest models like (`model.pt`) are too large to include directly in the repository. You can download them all using the [OneDrive Link](https://etsmtl365-my.sharepoint.com/:f:/r/personal/ghazal_danaee_1_ens_etsmtl_ca/Documents/Ghazal_Danaee_files/UNesT-trained-models/Unest14?csf=1&web=1&e=nKLPYC) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011bd65a-cf01-4f2d-b3dd-9ab10d921cde",
   "metadata": {},
   "source": [
    "## Inference \n",
    "Run inference 4 times using the following command. Each time with one of the trained models (model0, model1, model2, model3, model4) and change --saved_model_path and --fold according to the model you are using. The input to fold should be integers (0,1,2,3, and 4) which you should choose based on the model number. The results of different folds will be saved in folders fold0, fold1, fold2, fold3, fold4 in output_path/pred_0.7. Change the paths as needed.  \n",
    "  \n",
    "It is essential that you use the inference.py file in this repository and not the original in MASI Lab github page since their script is for 133 class segmentation.\n",
    "\n",
    "python inference.py --imagesTs_path test_images_path --saved_model_path path2saved_model --base_dir output_path --fold 0 --overlap 0.7 --device 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7d5c0e-fa6b-4c6d-a7f4-a5c9ff3bfd79",
   "metadata": {},
   "source": [
    "## Ensemble  \n",
    "If you perform the ensembling, you'll get slightly better results.  \n",
    "Run ensemble using the following command. Change the paths as needed.  \n",
    "\n",
    "python ensemble.py --prob_dir output_from_inference --img_path test_images_path --out_path output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf05aecb-2268-46f9-a1d8-24d99ea32b57",
   "metadata": {},
   "source": [
    "## Register back to original space\n",
    "In order to have final results, you'll need to register the data back to their original space. You can use the call_Run_Deep_brain.sh bash file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31e84fe-c370-4b26-a9d5-7d55718453c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075b44cd-de88-4642-96ae-591b8befa2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
